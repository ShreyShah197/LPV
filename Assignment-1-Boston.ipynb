{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f788c92c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.10.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (1.3.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (22.10.26)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (3.7.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (14.0.6)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (1.23.4)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (23.2)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (3.19.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (63.2.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (4.7.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (0.27.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (1.60.0)\n",
      "Requirement already satisfied: tensorboard<2.11,>=2.10 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (2.10.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.11,>=2.10.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: keras<2.11,>=2.10.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.25.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (5.2.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2022.9.24)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.11,>=2.10->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow --no-cache-dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e560506",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c866eec4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>b</th>\n",
       "      <th>lstat</th>\n",
       "      <th>medv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      crim    zn  indus  chas    nox     rm   age     dis  rad  tax  ptratio  \\\n",
       "0  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296     15.3   \n",
       "1  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242     17.8   \n",
       "2  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242     17.8   \n",
       "3  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222     18.7   \n",
       "4  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222     18.7   \n",
       "\n",
       "        b  lstat  medv  \n",
       "0  396.90   4.98  24.0  \n",
       "1  396.90   9.14  21.6  \n",
       "2  392.83   4.03  34.7  \n",
       "3  394.63   2.94  33.4  \n",
       "4  396.90   5.33  36.2  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('BostonHousing.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa8742c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.drop(columns=['Unnamed: 15','Unnamed: 16'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10e554b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['crim', 'zn', 'indus', 'chas', 'nox', 'rm', 'age', 'dis', 'rad', 'tax',\n",
       "       'ptratio', 'b', 'lstat', 'medv'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "945af192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 506 entries, 0 to 505\n",
      "Data columns (total 14 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   crim     506 non-null    float64\n",
      " 1   zn       506 non-null    float64\n",
      " 2   indus    506 non-null    float64\n",
      " 3   chas     506 non-null    int64  \n",
      " 4   nox      506 non-null    float64\n",
      " 5   rm       506 non-null    float64\n",
      " 6   age      506 non-null    float64\n",
      " 7   dis      506 non-null    float64\n",
      " 8   rad      506 non-null    int64  \n",
      " 9   tax      506 non-null    int64  \n",
      " 10  ptratio  506 non-null    float64\n",
      " 11  b        506 non-null    float64\n",
      " 12  lstat    506 non-null    float64\n",
      " 13  medv     506 non-null    float64\n",
      "dtypes: float64(11), int64(3)\n",
      "memory usage: 55.5 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "082476c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>b</th>\n",
       "      <th>lstat</th>\n",
       "      <th>medv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.613524</td>\n",
       "      <td>11.363636</td>\n",
       "      <td>11.136779</td>\n",
       "      <td>0.069170</td>\n",
       "      <td>0.554695</td>\n",
       "      <td>6.284634</td>\n",
       "      <td>68.574901</td>\n",
       "      <td>3.795043</td>\n",
       "      <td>9.549407</td>\n",
       "      <td>408.237154</td>\n",
       "      <td>18.455534</td>\n",
       "      <td>356.674032</td>\n",
       "      <td>12.653063</td>\n",
       "      <td>22.532806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.601545</td>\n",
       "      <td>23.322453</td>\n",
       "      <td>6.860353</td>\n",
       "      <td>0.253994</td>\n",
       "      <td>0.115878</td>\n",
       "      <td>0.702617</td>\n",
       "      <td>28.148861</td>\n",
       "      <td>2.105710</td>\n",
       "      <td>8.707259</td>\n",
       "      <td>168.537116</td>\n",
       "      <td>2.164946</td>\n",
       "      <td>91.294864</td>\n",
       "      <td>7.141062</td>\n",
       "      <td>9.197104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.006320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.385000</td>\n",
       "      <td>3.561000</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>1.129600</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>12.600000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>1.730000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.082045</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.190000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.449000</td>\n",
       "      <td>5.885500</td>\n",
       "      <td>45.025000</td>\n",
       "      <td>2.100175</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>279.000000</td>\n",
       "      <td>17.400000</td>\n",
       "      <td>375.377500</td>\n",
       "      <td>6.950000</td>\n",
       "      <td>17.025000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.256510</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.690000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.538000</td>\n",
       "      <td>6.208500</td>\n",
       "      <td>77.500000</td>\n",
       "      <td>3.207450</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>330.000000</td>\n",
       "      <td>19.050000</td>\n",
       "      <td>391.440000</td>\n",
       "      <td>11.360000</td>\n",
       "      <td>21.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.677083</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>18.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.624000</td>\n",
       "      <td>6.623500</td>\n",
       "      <td>94.075000</td>\n",
       "      <td>5.188425</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>666.000000</td>\n",
       "      <td>20.200000</td>\n",
       "      <td>396.225000</td>\n",
       "      <td>16.955000</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>88.976200</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>27.740000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.871000</td>\n",
       "      <td>8.780000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>12.126500</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>711.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>396.900000</td>\n",
       "      <td>37.970000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             crim          zn       indus        chas         nox          rm  \\\n",
       "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
       "mean     3.613524   11.363636   11.136779    0.069170    0.554695    6.284634   \n",
       "std      8.601545   23.322453    6.860353    0.253994    0.115878    0.702617   \n",
       "min      0.006320    0.000000    0.460000    0.000000    0.385000    3.561000   \n",
       "25%      0.082045    0.000000    5.190000    0.000000    0.449000    5.885500   \n",
       "50%      0.256510    0.000000    9.690000    0.000000    0.538000    6.208500   \n",
       "75%      3.677083   12.500000   18.100000    0.000000    0.624000    6.623500   \n",
       "max     88.976200  100.000000   27.740000    1.000000    0.871000    8.780000   \n",
       "\n",
       "              age         dis         rad         tax     ptratio           b  \\\n",
       "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
       "mean    68.574901    3.795043    9.549407  408.237154   18.455534  356.674032   \n",
       "std     28.148861    2.105710    8.707259  168.537116    2.164946   91.294864   \n",
       "min      2.900000    1.129600    1.000000  187.000000   12.600000    0.320000   \n",
       "25%     45.025000    2.100175    4.000000  279.000000   17.400000  375.377500   \n",
       "50%     77.500000    3.207450    5.000000  330.000000   19.050000  391.440000   \n",
       "75%     94.075000    5.188425   24.000000  666.000000   20.200000  396.225000   \n",
       "max    100.000000   12.126500   24.000000  711.000000   22.000000  396.900000   \n",
       "\n",
       "            lstat        medv  \n",
       "count  506.000000  506.000000  \n",
       "mean    12.653063   22.532806  \n",
       "std      7.141062    9.197104  \n",
       "min      1.730000    5.000000  \n",
       "25%      6.950000   17.025000  \n",
       "50%     11.360000   21.200000  \n",
       "75%     16.955000   25.000000  \n",
       "max     37.970000   50.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36ef32fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "crim       0\n",
       "zn         0\n",
       "indus      0\n",
       "chas       0\n",
       "nox        0\n",
       "rm         0\n",
       "age        0\n",
       "dis        0\n",
       "rad        0\n",
       "tax        0\n",
       "ptratio    0\n",
       "b          0\n",
       "lstat      0\n",
       "medv       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a25fc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling null values, if required\n",
    "# for i in df.columns:\n",
    "#     mean_value = df[i].mean()\n",
    "#     df[i].fillna(mean_value, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b716041",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lstat     -0.737663\n",
       "ptratio   -0.507787\n",
       "indus     -0.483725\n",
       "tax       -0.468536\n",
       "nox       -0.427321\n",
       "crim      -0.388305\n",
       "rad       -0.381626\n",
       "age       -0.376955\n",
       "chas       0.175260\n",
       "dis        0.249929\n",
       "b          0.333461\n",
       "zn         0.360445\n",
       "rm         0.695360\n",
       "medv       1.000000\n",
       "Name: medv, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr()['medv'].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5f5b648",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.loc[:, df.columns != 'medv']\n",
    "y = df.loc[:, df.columns == 'medv']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea673d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "mms = MinMaxScaler()\n",
    "mms.fit(X_train)\n",
    "X_train = mms.transform(X_train)\n",
    "X_test = mms.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ebff398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1 (Dense)             (None, 128)               1792      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_output (Dense)        (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,113\n",
      "Trainable params: 10,113\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(128, input_shape=(13, ), activation='relu', name='dense_1'))\n",
    "model.add(Dense(64, activation='relu', name='dense_2'))\n",
    "model.add(Dense(1, activation='linear', name='dense_output'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06a798ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "11/11 [==============================] - 1s 36ms/step - loss: 576.9185 - mae: 22.1203 - val_loss: 587.6448 - val_mae: 22.2558\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 526.3176 - mae: 20.8872 - val_loss: 526.6752 - val_mae: 20.7828\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 453.1661 - mae: 18.9395 - val_loss: 431.0839 - val_mae: 18.2091\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 345.0893 - mae: 15.7552 - val_loss: 302.5607 - val_mae: 14.2095\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 226.2448 - mae: 11.9768 - val_loss: 184.0805 - val_mae: 9.7579\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 153.9441 - mae: 9.7481 - val_loss: 135.1140 - val_mae: 8.4048\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 133.0442 - mae: 8.9712 - val_loss: 121.9480 - val_mae: 8.0150\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 116.0331 - mae: 8.2354 - val_loss: 113.4286 - val_mae: 7.6199\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 100.5414 - mae: 7.5082 - val_loss: 104.6109 - val_mae: 7.2273\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 87.4838 - mae: 6.9305 - val_loss: 94.5763 - val_mae: 6.8477\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 77.1630 - mae: 6.4100 - val_loss: 88.2008 - val_mae: 6.4569\n",
      "Epoch 12/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 68.0766 - mae: 5.9636 - val_loss: 81.9089 - val_mae: 6.2845\n",
      "Epoch 13/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 61.9423 - mae: 5.6677 - val_loss: 77.9851 - val_mae: 6.1626\n",
      "Epoch 14/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 57.1472 - mae: 5.4118 - val_loss: 74.2643 - val_mae: 6.1572\n",
      "Epoch 15/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 53.4996 - mae: 5.1493 - val_loss: 71.7942 - val_mae: 6.0367\n",
      "Epoch 16/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 50.5039 - mae: 4.9873 - val_loss: 69.3990 - val_mae: 5.9706\n",
      "Epoch 17/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 48.1759 - mae: 4.8664 - val_loss: 67.4385 - val_mae: 5.8637\n",
      "Epoch 18/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 46.2393 - mae: 4.7670 - val_loss: 65.4925 - val_mae: 5.7588\n",
      "Epoch 19/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 44.1859 - mae: 4.5964 - val_loss: 63.5795 - val_mae: 5.6747\n",
      "Epoch 20/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 42.1533 - mae: 4.5489 - val_loss: 61.5274 - val_mae: 5.6153\n",
      "Epoch 21/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 40.3116 - mae: 4.4405 - val_loss: 59.7432 - val_mae: 5.4740\n",
      "Epoch 22/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 38.3434 - mae: 4.2930 - val_loss: 57.7822 - val_mae: 5.3624\n",
      "Epoch 23/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 36.6280 - mae: 4.2159 - val_loss: 55.4507 - val_mae: 5.3138\n",
      "Epoch 24/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 34.9669 - mae: 4.1604 - val_loss: 53.8817 - val_mae: 5.1843\n",
      "Epoch 25/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 33.2757 - mae: 3.9783 - val_loss: 52.8661 - val_mae: 5.0270\n",
      "Epoch 26/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 31.7477 - mae: 3.8815 - val_loss: 50.6644 - val_mae: 4.9736\n",
      "Epoch 27/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 30.2415 - mae: 3.8055 - val_loss: 49.5070 - val_mae: 4.8465\n",
      "Epoch 28/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 28.8877 - mae: 3.7141 - val_loss: 47.0884 - val_mae: 4.8074\n",
      "Epoch 29/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 27.4341 - mae: 3.6079 - val_loss: 46.3028 - val_mae: 4.7530\n",
      "Epoch 30/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 26.3059 - mae: 3.5395 - val_loss: 44.2938 - val_mae: 4.7164\n",
      "Epoch 31/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 25.4542 - mae: 3.3770 - val_loss: 44.5267 - val_mae: 4.6461\n",
      "Epoch 32/100\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 24.7516 - mae: 3.4965 - val_loss: 40.7047 - val_mae: 4.6485\n",
      "Epoch 33/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 23.5050 - mae: 3.2485 - val_loss: 43.8043 - val_mae: 4.5456\n",
      "Epoch 34/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 22.3348 - mae: 3.2180 - val_loss: 38.6704 - val_mae: 4.5488\n",
      "Epoch 35/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 21.4724 - mae: 3.2047 - val_loss: 39.3027 - val_mae: 4.4794\n",
      "Epoch 36/100\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 20.9170 - mae: 3.0579 - val_loss: 39.0553 - val_mae: 4.4151\n",
      "Epoch 37/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 20.1372 - mae: 3.0951 - val_loss: 36.8310 - val_mae: 4.3829\n",
      "Epoch 38/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 19.5453 - mae: 3.0072 - val_loss: 37.9249 - val_mae: 4.2828\n",
      "Epoch 39/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 19.3585 - mae: 2.9467 - val_loss: 35.6949 - val_mae: 4.2453\n",
      "Epoch 40/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 18.5903 - mae: 2.9334 - val_loss: 34.9864 - val_mae: 4.2052\n",
      "Epoch 41/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 18.2968 - mae: 2.8993 - val_loss: 35.3167 - val_mae: 4.1199\n",
      "Epoch 42/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 17.8754 - mae: 2.8941 - val_loss: 34.0309 - val_mae: 4.0797\n",
      "Epoch 43/100\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 17.8996 - mae: 2.8443 - val_loss: 33.8054 - val_mae: 4.0268\n",
      "Epoch 44/100\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 17.3086 - mae: 2.7941 - val_loss: 34.3275 - val_mae: 4.0082\n",
      "Epoch 45/100\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 16.9434 - mae: 2.7818 - val_loss: 32.8846 - val_mae: 3.9463\n",
      "Epoch 46/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 16.8248 - mae: 2.8105 - val_loss: 31.9949 - val_mae: 3.8981\n",
      "Epoch 47/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 16.5933 - mae: 2.7456 - val_loss: 33.4254 - val_mae: 3.8718\n",
      "Epoch 48/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 16.4715 - mae: 2.7324 - val_loss: 32.0272 - val_mae: 3.8264\n",
      "Epoch 49/100\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 16.3492 - mae: 2.7601 - val_loss: 32.5309 - val_mae: 3.8066\n",
      "Epoch 50/100\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 16.1296 - mae: 2.6896 - val_loss: 31.4200 - val_mae: 3.7518\n",
      "Epoch 51/100\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 15.9407 - mae: 2.7176 - val_loss: 31.2208 - val_mae: 3.7191\n",
      "Epoch 52/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 15.7248 - mae: 2.6722 - val_loss: 31.3432 - val_mae: 3.6868\n",
      "Epoch 53/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 15.6558 - mae: 2.6734 - val_loss: 30.6029 - val_mae: 3.6492\n",
      "Epoch 54/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 15.6369 - mae: 2.6370 - val_loss: 30.7839 - val_mae: 3.6319\n",
      "Epoch 55/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 15.4861 - mae: 2.6773 - val_loss: 29.9594 - val_mae: 3.5783\n",
      "Epoch 56/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 15.2675 - mae: 2.6166 - val_loss: 29.9734 - val_mae: 3.5632\n",
      "Epoch 57/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 15.4752 - mae: 2.7037 - val_loss: 30.3825 - val_mae: 3.5745\n",
      "Epoch 58/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 15.1665 - mae: 2.5781 - val_loss: 29.2294 - val_mae: 3.5092\n",
      "Epoch 59/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 15.0152 - mae: 2.6605 - val_loss: 28.0875 - val_mae: 3.4608\n",
      "Epoch 60/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 15.2751 - mae: 2.6049 - val_loss: 29.6535 - val_mae: 3.4965\n",
      "Epoch 61/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 14.8262 - mae: 2.6397 - val_loss: 27.4204 - val_mae: 3.4053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 15.0586 - mae: 2.5843 - val_loss: 28.6220 - val_mae: 3.4157\n",
      "Epoch 63/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 14.5912 - mae: 2.5529 - val_loss: 27.2879 - val_mae: 3.3625\n",
      "Epoch 64/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 14.6231 - mae: 2.6250 - val_loss: 28.3417 - val_mae: 3.3709\n",
      "Epoch 65/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 14.6252 - mae: 2.5466 - val_loss: 27.0000 - val_mae: 3.3052\n",
      "Epoch 66/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 14.4801 - mae: 2.6285 - val_loss: 27.4177 - val_mae: 3.3079\n",
      "Epoch 67/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 14.3619 - mae: 2.5298 - val_loss: 28.2956 - val_mae: 3.3340\n",
      "Epoch 68/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 14.3338 - mae: 2.5974 - val_loss: 26.4130 - val_mae: 3.2669\n",
      "Epoch 69/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 14.0940 - mae: 2.5367 - val_loss: 27.3497 - val_mae: 3.2672\n",
      "Epoch 70/100\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 14.2022 - mae: 2.5482 - val_loss: 26.9996 - val_mae: 3.2443\n",
      "Epoch 71/100\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 14.5242 - mae: 2.6454 - val_loss: 26.5845 - val_mae: 3.2064\n",
      "Epoch 72/100\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 14.2951 - mae: 2.5380 - val_loss: 26.5498 - val_mae: 3.2019\n",
      "Epoch 73/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 13.7831 - mae: 2.5138 - val_loss: 25.5497 - val_mae: 3.1708\n",
      "Epoch 74/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 13.8451 - mae: 2.5152 - val_loss: 25.2007 - val_mae: 3.1177\n",
      "Epoch 75/100\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 13.7473 - mae: 2.5473 - val_loss: 26.0103 - val_mae: 3.1353\n",
      "Epoch 76/100\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 13.7604 - mae: 2.5119 - val_loss: 25.9279 - val_mae: 3.1122\n",
      "Epoch 77/100\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 13.4838 - mae: 2.4804 - val_loss: 24.2819 - val_mae: 3.1140\n",
      "Epoch 78/100\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 13.5722 - mae: 2.5020 - val_loss: 25.9281 - val_mae: 3.1184\n",
      "Epoch 79/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 13.4776 - mae: 2.4842 - val_loss: 25.0058 - val_mae: 3.0714\n",
      "Epoch 80/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 13.4448 - mae: 2.4747 - val_loss: 24.9265 - val_mae: 3.0628\n",
      "Epoch 81/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 13.4621 - mae: 2.5254 - val_loss: 25.0873 - val_mae: 3.0510\n",
      "Epoch 82/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 13.2586 - mae: 2.4767 - val_loss: 24.9041 - val_mae: 3.0320\n",
      "Epoch 83/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 13.1585 - mae: 2.4563 - val_loss: 24.2569 - val_mae: 3.0101\n",
      "Epoch 84/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 13.1149 - mae: 2.4522 - val_loss: 23.2777 - val_mae: 3.0055\n",
      "Epoch 85/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 13.0459 - mae: 2.4607 - val_loss: 23.9240 - val_mae: 2.9941\n",
      "Epoch 86/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 12.9839 - mae: 2.4508 - val_loss: 23.5503 - val_mae: 2.9702\n",
      "Epoch 87/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 12.9011 - mae: 2.4422 - val_loss: 23.0692 - val_mae: 2.9462\n",
      "Epoch 88/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 12.7932 - mae: 2.4189 - val_loss: 22.5696 - val_mae: 2.9373\n",
      "Epoch 89/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 12.7397 - mae: 2.4383 - val_loss: 23.2345 - val_mae: 2.9385\n",
      "Epoch 90/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 12.7307 - mae: 2.4065 - val_loss: 21.9007 - val_mae: 2.9126\n",
      "Epoch 91/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 12.6892 - mae: 2.4201 - val_loss: 22.6295 - val_mae: 2.8986\n",
      "Epoch 92/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 12.6588 - mae: 2.4517 - val_loss: 22.8221 - val_mae: 2.8925\n",
      "Epoch 93/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 12.6882 - mae: 2.3843 - val_loss: 21.5430 - val_mae: 2.8432\n",
      "Epoch 94/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 12.4646 - mae: 2.3905 - val_loss: 21.5023 - val_mae: 2.8532\n",
      "Epoch 95/100\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 12.3962 - mae: 2.4189 - val_loss: 21.6415 - val_mae: 2.8415\n",
      "Epoch 96/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 12.4696 - mae: 2.3820 - val_loss: 20.8938 - val_mae: 2.8252\n",
      "Epoch 97/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 12.3791 - mae: 2.4278 - val_loss: 22.5953 - val_mae: 2.9078\n",
      "Epoch 98/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 12.3211 - mae: 2.3587 - val_loss: 20.9466 - val_mae: 2.7957\n",
      "Epoch 99/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 12.2570 - mae: 2.4150 - val_loss: 21.5575 - val_mae: 2.8207\n",
      "Epoch 100/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 12.2809 - mae: 2.3771 - val_loss: 21.1305 - val_mae: 2.7772\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=100, validation_split=0.05, verbose = 1)                                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4687d251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 3ms/step - loss: 21.9256 - mae: 3.0217\n",
      "Mean squared error on test data:  21.925617218017578\n",
      "Mean absolute error on test data:  3.0216662883758545\n"
     ]
    }
   ],
   "source": [
    "mse_nn, mae_nn = model.evaluate(X_test, y_test)\n",
    "\n",
    "print('Mean squared error on test data: ', mse_nn)\n",
    "print('Mean absolute error on test data: ', mae_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a0cc4279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "y1 = model.predict(X_test[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4856bbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps=[]\n",
    "for i in y1:\n",
    "    ps.append(list(i)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3251b3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.DataFrame({'actual':y_test['medv'],'predicted':ps})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fccc2196",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>medv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>26.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>45.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>20.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>34.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     medv\n",
       "410  15.0\n",
       "85   26.6\n",
       "280  45.4\n",
       "422  20.8\n",
       "199  34.9"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eca3d0ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>15.0</td>\n",
       "      <td>13.784587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>26.6</td>\n",
       "      <td>26.996046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>45.4</td>\n",
       "      <td>42.889954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>20.8</td>\n",
       "      <td>16.109205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>34.9</td>\n",
       "      <td>28.152342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>21.9</td>\n",
       "      <td>44.351555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>28.7</td>\n",
       "      <td>25.567730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>7.2</td>\n",
       "      <td>11.070492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>20.0</td>\n",
       "      <td>15.617468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>32.2</td>\n",
       "      <td>29.457340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     actual  predicted\n",
       "410    15.0  13.784587\n",
       "85     26.6  26.996046\n",
       "280    45.4  42.889954\n",
       "422    20.8  16.109205\n",
       "199    34.9  28.152342\n",
       "364    21.9  44.351555\n",
       "5      28.7  25.567730\n",
       "415     7.2  11.070492\n",
       "209    20.0  15.617468\n",
       "284    32.2  29.457340"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1dcd13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
